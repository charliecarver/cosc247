{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sam ML class playground",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knBAhm4gBusj",
        "outputId": "6b93fa4c-f2d1-464c-903d-7ecb049affb8"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD8za_DO-dsY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk.tokenize\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict\n",
        "import sklearn.model_selection\n",
        "import sklearn.metrics\n",
        "import sklearn.naive_bayes\n",
        "import sklearn.tree \n",
        "import string\n",
        "\n",
        "COMMON_WORD_THRESHOLD = 400\n",
        "\n",
        "def tokenize_without_stopwords(review, stop_words, ngram_size):\n",
        "    if type(review) == str:\n",
        "        tokenized = nltk.tokenize.word_tokenize(review)\n",
        "\n",
        "        return nltk.ngrams([word for word in tokenized if (word not in string.punctuation) and (word not in stop_words) and (word != 'quot') and (word != \"''\") and (word != \"``\")], ngram_size)\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def get_ground_truth_for_sentiment_classification_training(training_data, positive_or_negative):\n",
        "    predicted_variable = np.zeros(len(training_data), dtype=np.int8)\n",
        "    \n",
        "    if positive_or_negative == 'positive':\n",
        "        for row_idx, data_row in training_data.iterrows():\n",
        "            if data_row['overall'] >= 4:\n",
        "                predicted_variable[row_idx] = 1\n",
        "    \n",
        "    elif positive_or_negative == 'negative':\n",
        "        for row_idx, data_row in training_data.iterrows():\n",
        "            if data_row['overall'] <= 2:\n",
        "                predicted_variable[row_idx] = 1\n",
        "    else:\n",
        "      raise Exception(\"Unrecognized sentiment type!\")\n",
        "\n",
        "    return predicted_variable\n",
        "\n",
        "\n",
        "def format_data_for_review_sentiment_classification(training_data, common_word_threshold, column_name, ngram_size):\n",
        "    training_data[column_name] = training_data[column_name].apply(\n",
        "        lambda x: x.lower() if not type(x) == float else x\n",
        "    )\n",
        "    word_frequency = defaultdict(lambda: 0)\n",
        "\n",
        "    stop_words_set = set(stopwords.words('english'))\n",
        "\n",
        "    print(\"Building word frequency dictionary...\")\n",
        "    for review in training_data[column_name]:\n",
        "        review_words = tokenize_without_stopwords(review, stop_words_set, ngram_size)\n",
        "\n",
        "        for word in review_words:\n",
        "            word_frequency[word] = word_frequency[word] + 1\n",
        "\n",
        "    common_words = [\n",
        "        word for word, freq in word_frequency.items() if freq > common_word_threshold\n",
        "    ]\n",
        "\n",
        "    common_words.sort(key=lambda word: word_frequency[word], reverse=True)\n",
        "\n",
        "    print(\"Common words: \", common_words[0:50])\n",
        "\n",
        "    print(\"Number of unique words\", len(word_frequency))\n",
        "    print(\"Number words that appear more than {} times\".format(common_word_threshold), len(\n",
        "        common_words\n",
        "    ))\n",
        "\n",
        "    print(\"Getting unique id for each word...\")\n",
        "    index_by_word = {}\n",
        "\n",
        "    for index, word in enumerate(common_words):\n",
        "        index_by_word[word] = index\n",
        "\n",
        "    print(\"Creating traning matrix\")\n",
        "    data = np.zeros((len(training_data), len(common_words)), dtype=float)\n",
        "    for row_idx, data_row in training_data.iterrows():\n",
        "        review_words = tokenize_without_stopwords(data_row[column_name], stop_words_set, ngram_size)\n",
        "\n",
        "        for word in review_words:\n",
        "            if word in index_by_word:\n",
        "                word_idx = index_by_word[word]\n",
        "                data[row_idx][word_idx] = data[row_idx][word_idx] + 1\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def train_review_sentiment_classifier(dataframe, common_word_threshold, column_name, ngram_size, positive_or_negative):\n",
        "    print(\"Training sentiment classifier on column {} with common word threshold {}\".format(column_name, common_word_threshold))\n",
        "    data = format_data_for_review_sentiment_classification(\n",
        "        dataframe, common_word_threshold, column_name, ngram_size\n",
        "    )\n",
        "\n",
        "    ground_truth = get_ground_truth_for_sentiment_classification_training(dataframe, positive_or_negative)\n",
        "\n",
        "    clf = sklearn.tree.DecisionTreeClassifier(max_depth=6)\n",
        "    #clf = sklearn.naive_bayes.GaussianNB()\n",
        "    return clf.fit(data, ground_truth)\n",
        "\n",
        "\n",
        "def add_review_sentiment_column_into_data(dataframe, trained_classifier, from_colname, to_colname, ngram_size):\n",
        "    formatted_review_data = format_data_for_review_sentiment_classification(\n",
        "        dataframe, COMMON_WORD_THRESHOLD, from_colname, ngram_size\n",
        "    )\n",
        "\n",
        "    positive_predictions = trained_classifier.predict(formatted_review_data)\n",
        "\n",
        "    return dataframe.assign(**{to_colname: positive_predictions})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov14Y8WF_2ih"
      },
      "source": [
        "training_data = pd.read_csv(\"Train.csv\")\n",
        "testing_data = pd.read_csv(\"Test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BPYpm5w_8kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6413b13-59ea-415d-cb03-3f1ec562b31d"
      },
      "source": [
        "print(\"~~~~~~~~~~~~~~ POSITIVE SENTIMENT ANALYSIS~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Training sentiment classifier on full text!\")\n",
        "trained_positive_review_classifier = train_review_sentiment_classifier(\n",
        "    training_data,\n",
        "    COMMON_WORD_THRESHOLD,\n",
        "    'reviewText',\n",
        "    2,\n",
        "    'positive'\n",
        ")\n",
        "trained_positive_review_summary_classifier = train_review_sentiment_classifier(\n",
        "    training_data,\n",
        "    COMMON_WORD_THRESHOLD,\n",
        "    'summary',\n",
        "    1,\n",
        "    'positive'\n",
        ")\n",
        "print(\"Annotating training data with positive column!\")\n",
        "training_data = add_review_sentiment_column_into_data(training_data, trained_positive_review_classifier, 'reviewText', 'positive_review_text', 2)\n",
        "training_data = add_review_sentiment_column_into_data(training_data, trained_positive_review_summary_classifier, 'summary', 'positive_review_summary', 1)\n",
        "\n",
        "positive_ground_truth = get_ground_truth_for_sentiment_classification_training(training_data, 'negative')\n",
        "positive_predictions_from_text = training_data['positive_review_text'].to_numpy(dtype=np.int8)\n",
        "\n",
        "positive_predictions_from_summary = training_data['positive_review_summary'].to_numpy(dtype=np.int8)\n",
        "\n",
        "f1_text = sklearn.metrics.f1_score(ground_truth, positive_predictions_from_text)\n",
        "accuracy_text = sklearn.metrics.accuracy_score(ground_truth, positive_predictions_from_text)\n",
        "\n",
        "f1_summary = sklearn.metrics.f1_score(ground_truth, positive_predictions_from_summary)\n",
        "accuracy_summary = sklearn.metrics.accuracy_score(ground_truth, positive_predictions_from_summary)\n",
        "\n",
        "print(\"Evaluating positive sentiment classifier on full review text\")\n",
        "print(\"F1 {}, Accuracy {}\".format(f1_text, accuracy_text))\n",
        "\n",
        "print(\"performance on positive summary\")\n",
        "print(\"F1 {}, Accuracy {}\".format(f1_summary, accuracy_summary))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~ POSITIVE SENTIMENT ANALYSIS~~~~~~~~~~~~~~~~~~~~~\n",
            "Training sentiment classifier on full text!\n",
            "Training sentiment classifier on column reviewText with common word threshold 400\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training sentiment classifier on column summary with common word threshold 400\n",
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Annotating training data with positive column!\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Evaluating positive sentiment classifier on full review text\n",
            "F1 0.8335672127356533, Accuracy 0.7149633656771499\n",
            "performance on positive summary\n",
            "F1 0.8347126158254886, Accuracy 0.7175736736934958\n",
            "~~~~~~~~~~~~~~~~~~~~~~ NEGATIVE SENTIMENT ANALYSIS~~~~~~~~~~~~~~~\n",
            "Training sentiment classifier on full text!\n",
            "Training sentiment classifier on column reviewText with common word threshold 400\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training sentiment classifier on column summary with common word threshold 400\n",
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Annotating training data with positive column!\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Evaluating negative sentiment classifier on full review text\n",
            "F1 0.00017632241813602016, Accuracy 0.28544168211848997\n",
            "performance on negative summary\n",
            "F1 5.037402715160063e-05, Accuracy 0.2852976651244847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsBNZtz_9mFn",
        "outputId": "83d8e3bf-0c7a-438e-d68c-8412df3ef3c9"
      },
      "source": [
        "print(\"~~~~~~~~~~~~~~~~~~~~~~ NEGATIVE SENTIMENT ANALYSIS~~~~~~~~~~~~~~~\")\r\n",
        "print(\"Training sentiment classifier on full text!\")\r\n",
        "trained_negative_review_classifier = train_review_sentiment_classifier(\r\n",
        "    training_data,\r\n",
        "    COMMON_WORD_THRESHOLD,\r\n",
        "    'reviewText',\r\n",
        "    2,\r\n",
        "    'negative'\r\n",
        ")\r\n",
        "trained_negative_review_summary_classifier = train_review_sentiment_classifier(\r\n",
        "    training_data,\r\n",
        "    COMMON_WORD_THRESHOLD,\r\n",
        "    'summary',\r\n",
        "    1,\r\n",
        "    'negative'\r\n",
        ")\r\n",
        "print(\"Annotating training data with positive column!\")\r\n",
        "training_data = add_review_sentiment_column_into_data(training_data, trained_negative_review_classifier, 'reviewText', 'negative_review_text', 2)\r\n",
        "training_data = add_review_sentiment_column_into_data(training_data, trained_negative_review_summary_classifier, 'summary', 'negative_review_summary', 1)\r\n",
        "\r\n",
        "negative_ground_truth = get_ground_truth_for_sentiment_classification_training(training_data, 'negative')\r\n",
        "negative_predictions_from_text = training_data['negative_review_text'].to_numpy(dtype=np.int8)\r\n",
        "\r\n",
        "negative_predictions_from_summary = training_data['negative_review_summary'].to_numpy(dtype=np.int8)\r\n",
        "\r\n",
        "f1_text = sklearn.metrics.f1_score(negative_ground_truth, negative_predictions_from_text)\r\n",
        "accuracy_text = sklearn.metrics.accuracy_score(negative_ground_truth, negative_predictions_from_text)\r\n",
        "\r\n",
        "f1_summary = sklearn.metrics.f1_score(ground_truth, negative_predictions_from_summary)\r\n",
        "accuracy_summary = sklearn.metrics.accuracy_score(ground_truth, negative_predictions_from_summary)\r\n",
        "\r\n",
        "print(\"Evaluating negative sentiment classifier on full review text\")\r\n",
        "print(\"F1 {}, Accuracy {}\".format(f1_text, accuracy_text))\r\n",
        "\r\n",
        "print(\"performance on negative summary\")\r\n",
        "print(\"F1 {}, Accuracy {}\".format(f1_summary, accuracy_summary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~ NEGATIVE SENTIMENT ANALYSIS~~~~~~~~~~~~~~~\n",
            "Training sentiment classifier on full text!\n",
            "Training sentiment classifier on column reviewText with common word threshold 400\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training sentiment classifier on column summary with common word threshold 400\n",
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Annotating training data with positive column!\n",
            "Building word frequency dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Common words:  [('ca', \"n't\"), ('one', 'best'), ('cd', \"'s\"), ('wo', \"n't\"), ('pink', 'floyd'), ('sounds', 'like'), ('every', 'song'), (\"'s\", 'voice'), (\"'s\", 'music'), ('album', \"'s\"), (\"n't\", 'know'), ('...', '...'), (\"n't\", 'get'), ('highly', 'recommend'), (\"'s\", 'best'), ('first', 'time'), ('great', 'album'), ('years', 'ago'), ('love', 'cd'), (\"'s\", 'great'), ('songs', 'like'), ('one', 'favorite'), ('abbey', 'road'), ('songs', 'album'), ('could', \"n't\"), (\"n't\", 'like'), ('sound', 'like'), ('great', 'cd'), ('ever', 'heard'), ('even', 'though'), ('title', 'track'), ('much', 'better'), (\"'ve\", 'heard'), ('long', 'time'), ('great', 'music'), ('song', 'album'), ('bought', 'cd'), ('sound', 'quality'), ('great', 'songs'), (\"'s\", 'good'), ('would', \"n't\"), (\"n't\", 'think'), ('white', 'album'), ('never', 'heard'), ('really', 'good'), ('buy', 'cd'), ('would', 'recommend'), ('--', '--'), ('best', 'album'), (\"'s\", 'one')]\n",
            "Number of unique words 3113742\n",
            "Number words that appear more than 400 times 508\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building word frequency dictionary...\n",
            "Common words:  [('great',), ('...',), ('cd',), ('album',), ('music',), ('best',), (\"'s\",), ('good',), ('love',), ('one',), ('awesome',), ('excellent',), ('christmas',), ('beautiful',), ('soundtrack',), (\"n't\",), ('beatles',), ('amazing',), ('wonderful',), ('classic',), ('songs',), ('ever',), ('better',), ('like',), ('new',), ('stars',), ('time',), ('another',), ('movie',), ('voice',), ('favorite',), ('still',), ('sound',), ('fantastic',), ('collection',), ('score',), ('must',), ('nice',), ('back',), ('song',), ('rock',), ('buy',), ('fun',), ('get',), ('review',), ('greatest',), ('wow',), ('perfect',), ('band',), ('really',)]\n",
            "Number of unique words 27690\n",
            "Number words that appear more than 400 times 97\n",
            "Getting unique id for each word...\n",
            "Creating traning matrix\n",
            "Evaluating negative sentiment classifier on full review text\n",
            "F1 0.014109347442680775, Accuracy 0.9295576878071612\n",
            "performance on negative summary\n",
            "F1 5.037402715160063e-05, Accuracy 0.2852976651244847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djUJLQ94EKxc"
      },
      "source": [
        "%load_ext google.colab.data_table\r\n",
        "training_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dse4wjg3Q5kr"
      },
      "source": [
        "import json\r\n",
        "def clean_helpful_column(data):\r\n",
        "  if type(data) == float:\r\n",
        "    return 0.0\r\n",
        "\r\n",
        "  parsed = json.loads(data)\r\n",
        "  if parsed[1] == 0:\r\n",
        "    return 0.0\r\n",
        "    \r\n",
        "  return float(parsed[0]) / float(parsed[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBigzX1fNcl-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cb46024-35d2-493f-d1a3-9e2e8c20dd73"
      },
      "source": [
        "training_data['helpful'] = training_data['helpful'].apply(lambda x: clean_helpful_column(x))\r\n",
        "training_data['positive_helpful'] = np.where((training_data['helpful'] > 0.1) & (training_data['positive_review_text'] == 1), True, False)\r\n",
        "training_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>amazon-id</th>\n",
              "      <th>helpful</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>summary</th>\n",
              "      <th>price</th>\n",
              "      <th>categories</th>\n",
              "      <th>root-genre</th>\n",
              "      <th>title</th>\n",
              "      <th>artist</th>\n",
              "      <th>label</th>\n",
              "      <th>first-release-year</th>\n",
              "      <th>songs</th>\n",
              "      <th>salesRank</th>\n",
              "      <th>related</th>\n",
              "      <th>positive_review_text</th>\n",
              "      <th>positive_review_summary</th>\n",
              "      <th>positive_helpful</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4984057859803657856</td>\n",
              "      <td>1877521326299865484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1302739200</td>\n",
              "      <td>very nice music for practicing my tai chi. i d...</td>\n",
              "      <td>4</td>\n",
              "      <td>04 14, 2011</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>16.47</td>\n",
              "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
              "      <td>New Age</td>\n",
              "      <td>-3267874170410107454</td>\n",
              "      <td>-7180760356347753735</td>\n",
              "      <td>Cdbaby/Cdbaby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
              "      <td>27222</td>\n",
              "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9136764282801708742</td>\n",
              "      <td>1877521326299865484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1180396800</td>\n",
              "      <td>i recently starting doing tai chi which i love...</td>\n",
              "      <td>5</td>\n",
              "      <td>05 29, 2007</td>\n",
              "      <td>tranquillity in motion !!!</td>\n",
              "      <td>16.47</td>\n",
              "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
              "      <td>New Age</td>\n",
              "      <td>-3267874170410107454</td>\n",
              "      <td>-7180760356347753735</td>\n",
              "      <td>Cdbaby/Cdbaby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
              "      <td>27222</td>\n",
              "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2164551966908582519</td>\n",
              "      <td>1877521326299865484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1361404800</td>\n",
              "      <td>my wife uses it for her class room the kids lo...</td>\n",
              "      <td>5</td>\n",
              "      <td>02 21, 2013</td>\n",
              "      <td>great stuff</td>\n",
              "      <td>16.47</td>\n",
              "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
              "      <td>New Age</td>\n",
              "      <td>-3267874170410107454</td>\n",
              "      <td>-7180760356347753735</td>\n",
              "      <td>Cdbaby/Cdbaby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
              "      <td>27222</td>\n",
              "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-7309200698931694843</td>\n",
              "      <td>1877521326299865484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1338163200</td>\n",
              "      <td>we bought this music to go dr lam dvd. the mus...</td>\n",
              "      <td>5</td>\n",
              "      <td>05 28, 2012</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>16.47</td>\n",
              "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
              "      <td>New Age</td>\n",
              "      <td>-3267874170410107454</td>\n",
              "      <td>-7180760356347753735</td>\n",
              "      <td>Cdbaby/Cdbaby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
              "      <td>27222</td>\n",
              "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4461682407031037732</td>\n",
              "      <td>1877521326299865484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1396310400</td>\n",
              "      <td>it helps me do my exercise because it sets the...</td>\n",
              "      <td>5</td>\n",
              "      <td>04 1, 2014</td>\n",
              "      <td>tai chi music</td>\n",
              "      <td>16.47</td>\n",
              "      <td>['CDs &amp; Vinyl', 'New Age']</td>\n",
              "      <td>New Age</td>\n",
              "      <td>-3267874170410107454</td>\n",
              "      <td>-7180760356347753735</td>\n",
              "      <td>Cdbaby/Cdbaby</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[7058439142327364074, 6037075874942075284, 852...</td>\n",
              "      <td>27222</td>\n",
              "      <td>{'also_bought': [-404470919165672227, 11968160...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111093</th>\n",
              "      <td>-508419005999372045</td>\n",
              "      <td>-272019625357917459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1405900800</td>\n",
              "      <td>nice soundtrack and i was pleasantly surprised...</td>\n",
              "      <td>4</td>\n",
              "      <td>07 21, 2014</td>\n",
              "      <td>four stars</td>\n",
              "      <td>33.76</td>\n",
              "      <td>['CDs &amp; Vinyl', 'Pop']</td>\n",
              "      <td>Pop</td>\n",
              "      <td>-4806325396575401230</td>\n",
              "      <td>-3758738156872779256</td>\n",
              "      <td>222 Records/Interscope</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>[-1473205402332670702, 4962016810493850163, -1...</td>\n",
              "      <td>6</td>\n",
              "      <td>{'also_bought': [1108107143497525752, -5941116...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111094</th>\n",
              "      <td>4690686471314282919</td>\n",
              "      <td>-272019625357917459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1405209600</td>\n",
              "      <td>i'd you are looking for the music that they sa...</td>\n",
              "      <td>5</td>\n",
              "      <td>07 13, 2014</td>\n",
              "      <td>i'd you are looking for the music that they sa...</td>\n",
              "      <td>33.76</td>\n",
              "      <td>['CDs &amp; Vinyl', 'Pop']</td>\n",
              "      <td>Pop</td>\n",
              "      <td>-4806325396575401230</td>\n",
              "      <td>-3758738156872779256</td>\n",
              "      <td>222 Records/Interscope</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>[-1473205402332670702, 4962016810493850163, -1...</td>\n",
              "      <td>6</td>\n",
              "      <td>{'also_bought': [1108107143497525752, -5941116...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111095</th>\n",
              "      <td>-6735807132142826990</td>\n",
              "      <td>-272019625357917459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1404259200</td>\n",
              "      <td>fantastic film!  loved this movie and the musi...</td>\n",
              "      <td>5</td>\n",
              "      <td>07 2, 2014</td>\n",
              "      <td>fantastic film! loved this movie and the music</td>\n",
              "      <td>33.76</td>\n",
              "      <td>['CDs &amp; Vinyl', 'Pop']</td>\n",
              "      <td>Pop</td>\n",
              "      <td>-4806325396575401230</td>\n",
              "      <td>-3758738156872779256</td>\n",
              "      <td>222 Records/Interscope</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>[-1473205402332670702, 4962016810493850163, -1...</td>\n",
              "      <td>6</td>\n",
              "      <td>{'also_bought': [1108107143497525752, -5941116...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111096</th>\n",
              "      <td>6536263939078780437</td>\n",
              "      <td>2197509461459270640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1404518400</td>\n",
              "      <td>a great new cd with uptempo, funky guitar. thi...</td>\n",
              "      <td>5</td>\n",
              "      <td>07 5, 2014</td>\n",
              "      <td>a great new cd with uptempo</td>\n",
              "      <td>32.98</td>\n",
              "      <td>['CDs &amp; Vinyl', 'Jazz', 'Smooth Jazz']</td>\n",
              "      <td>Jazz</td>\n",
              "      <td>5145278291721917176</td>\n",
              "      <td>2800811401610696293</td>\n",
              "      <td>Nuance Music Group</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>[4589355438812792687, -640221404018307482, 897...</td>\n",
              "      <td>24972</td>\n",
              "      <td>{'also_bought': [314388363399769352, 111945196...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111097</th>\n",
              "      <td>7775132336760021809</td>\n",
              "      <td>2197509461459270640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1404691200</td>\n",
              "      <td>great follow up cd, great smooth jazz with jus...</td>\n",
              "      <td>5</td>\n",
              "      <td>07 7, 2014</td>\n",
              "      <td>matt marshak does it again!</td>\n",
              "      <td>32.98</td>\n",
              "      <td>['CDs &amp; Vinyl', 'Jazz', 'Smooth Jazz']</td>\n",
              "      <td>Jazz</td>\n",
              "      <td>5145278291721917176</td>\n",
              "      <td>2800811401610696293</td>\n",
              "      <td>Nuance Music Group</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>[4589355438812792687, -640221404018307482, 897...</td>\n",
              "      <td>24972</td>\n",
              "      <td>{'also_bought': [314388363399769352, 111945196...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111098 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 reviewerID  ...  positive_helpful\n",
              "0      -4984057859803657856  ...             False\n",
              "1       9136764282801708742  ...             False\n",
              "2       2164551966908582519  ...             False\n",
              "3      -7309200698931694843  ...             False\n",
              "4      -4461682407031037732  ...             False\n",
              "...                     ...  ...               ...\n",
              "111093  -508419005999372045  ...             False\n",
              "111094  4690686471314282919  ...             False\n",
              "111095 -6735807132142826990  ...             False\n",
              "111096  6536263939078780437  ...             False\n",
              "111097  7775132336760021809  ...             False\n",
              "\n",
              "[111098 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owZsn7HhF1nC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "e810a296-cc43-4b7c-dcd4-e1654679312e"
      },
      "source": [
        "product_data = training_data.groupby('amazon-id').agg({\r\n",
        "    'positive_review_text': 'sum',\r\n",
        "    'overall': 'mean',\r\n",
        "    'reviewText': 'count',\r\n",
        "    'salesRank': 'mean',\r\n",
        "    'positive_helpful': 'sum',\r\n",
        "    'positive_review_summary': 'sum',\r\n",
        "    'negative_review_summary': 'sum',\r\n",
        "    'negative_review_text': 'sum'\r\n",
        "    })\r\n",
        "product_data['awesome'] = np.where(product_data['overall'] >= 4.5, True, False)\r\n",
        "product_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive_review_text</th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>salesRank</th>\n",
              "      <th>positive_helpful</th>\n",
              "      <th>positive_review_summary</th>\n",
              "      <th>awesome</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amazon-id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-9217723718720870868</th>\n",
              "      <td>9.0</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>9</td>\n",
              "      <td>1310516</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9215746463819797371</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>309139</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9213978596308513604</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>280309</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9211290576571923870</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>2</td>\n",
              "      <td>321654</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9208769561690910545</th>\n",
              "      <td>16.0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>16</td>\n",
              "      <td>17515</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9218870320655141661</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>2</td>\n",
              "      <td>1760050</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221578337502519209</th>\n",
              "      <td>8.0</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>8</td>\n",
              "      <td>149220</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221615570697142155</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>600235</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9221801008952598876</th>\n",
              "      <td>18.0</td>\n",
              "      <td>4.388889</td>\n",
              "      <td>18</td>\n",
              "      <td>271266</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9222652928856141170</th>\n",
              "      <td>12.0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>12</td>\n",
              "      <td>589810</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10543 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      positive_review_text  ...  awesome\n",
              "amazon-id                                   ...         \n",
              "-9217723718720870868                   9.0  ...    False\n",
              "-9215746463819797371                   4.0  ...     True\n",
              "-9213978596308513604                   1.0  ...    False\n",
              "-9211290576571923870                   2.0  ...     True\n",
              "-9208769561690910545                  16.0  ...     True\n",
              "...                                    ...  ...      ...\n",
              " 9218870320655141661                   1.0  ...    False\n",
              " 9221578337502519209                   8.0  ...     True\n",
              " 9221615570697142155                   2.0  ...     True\n",
              " 9221801008952598876                  18.0  ...    False\n",
              " 9222652928856141170                  12.0  ...     True\n",
              "\n",
              "[10543 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwJSJqnzMjEE"
      },
      "source": [
        "training_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67_EwUQXHZ6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09340e79-ba57-4223-a698-d23ff97cfa23"
      },
      "source": [
        "independent_variables = product_data[['positive_review_text', 'positive_review_summary', 'reviewText', 'positive_helpful', 'negative_review_text', 'negative_review_summary']].to_numpy()\r\n",
        "dependent_variables = product_data['awesome'].to_numpy(dtype=np.int8)\r\n",
        "independent_variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.,  9.,  9.,  0.],\n",
              "       [ 4.,  4.,  4.,  0.],\n",
              "       [ 1.,  0.,  1.,  0.],\n",
              "       ...,\n",
              "       [ 2.,  2.,  2.,  0.],\n",
              "       [18., 13., 18.,  0.],\n",
              "       [12., 12., 12.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29SHw0MwJY32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f9de07-ed60-4e3b-ff81-20241e3cc153"
      },
      "source": [
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(independent_variables, dependent_variables, test_size=0.4)\r\n",
        "clf = sklearn.naive_bayes.GaussianNB()\r\n",
        "trained = clf.fit(X_train, y_train)\r\n",
        "trained.predict(X_test)\r\n",
        "\r\n",
        "f1_score = sklearn.metrics.f1_score(y_test, trained.predict(X_test))\r\n",
        "accuracy = sklearn.metrics.accuracy_score(y_test, trained.predict(X_test))\r\n",
        "\r\n",
        "print(\"Accuracy {} F1 {}\".format(f1_score, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.7859741015568167 F1 0.6512565196775723\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}