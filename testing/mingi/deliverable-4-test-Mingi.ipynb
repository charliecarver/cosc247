{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/charliecarver/cosc247/blob/master/deliverable-3/deliverable-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYRuPMqIMD8l",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load CSV files from remote repo\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "r = requests.get('https://github.com/charliecarver/cosc247/blob/master/datasets.zip?raw=true')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "testPath = 'Test.csv'\n",
    "trainPath = 'Train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOxV2DdNMD8v"
   },
   "source": [
    "## Single-File Deliverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tkgyQiZ9MD8v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lupan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lupan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lupan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lupan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import string\n",
    "from ast import literal_eval\n",
    "import nltk.tokenize\n",
    "import nltk.stem.porter\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn.metrics\n",
    "import statistics\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from timeit import default_timer as timer\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import statistics\n",
    "import nltk\n",
    "import sklearn.feature_selection\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Flags\n",
    "useTestCSV = False\n",
    "#NGRAM_SIZE = 2\n",
    "NGRAM_SIZE = 4\n",
    "#COMMON_WORD_THRESHOLD = 10\n",
    "COMMON_WORD_THRESHOLD = 4\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def preprocessForTextClassification(df):\n",
    "    df['reviewText'] = df['reviewText'].fillna(\"\")\n",
    "    df['summary'] = df['summary'].fillna(\"\")\n",
    "\n",
    "    P = df.groupby('amazon-id').agg({\n",
    "        'reviewText': ' '.join,\n",
    "        'summary': ' '.join,\n",
    "    })\n",
    "\n",
    "    P['reviewText'] = P['reviewText'] + \" \" + P['summary']\n",
    "\n",
    "    return P\n",
    "\n",
    "\n",
    "# Train text classifier\n",
    "def trainTextFrequency(df):\n",
    "    P = preprocessForTextClassification(df)\n",
    "\n",
    "    #vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(1,NGRAM_SIZE))\n",
    "    vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(1,NGRAM_SIZE), min_df=COMMON_WORD_THRESHOLD, preprocessor=lambda token: stemmer.stem(token))\n",
    "    X1 = vectorizer.fit_transform(P['reviewText'])\n",
    "\n",
    "    return X1, vectorizer\n",
    "\n",
    "def getTextMatrix(df, word_indices):\n",
    "    P = preprocessForTextClassification(df)\n",
    "\n",
    "    X1 = word_indices.transform(P['reviewText'])\n",
    "    return X1\n",
    "\n",
    "# function for normalization\n",
    "def normalize_column_data(input_data):\n",
    "    for feature in input_data:    \n",
    "        input_data[feature] = (input_data[feature]-input_data[feature].min())/(input_data[feature].max()-input_data[feature].min())\n",
    "\n",
    "# Process numerical data\n",
    "def processNumerical(df):\n",
    "\n",
    "    # Drop text data\n",
    "    df = df.drop(columns=['title', 'categories', 'songs', 'related', 'reviewTime'])\n",
    "\n",
    "    # Drop columns that need more time to process\n",
    "    #df = df.drop(columns=['label', 'first-release-year'])\n",
    "    df = df.drop(columns=['label'])\n",
    "    df['first-release-year'].fillna((df['first-release-year'].median()), inplace=True)\n",
    "    df['first-release-year'] = df['first-release-year'].apply(lambda x: 1 if x > 1990 else 0)\n",
    "    \n",
    "    # Transform helpful into \"ratio\" of being helpful\n",
    "    df['helpful'] = df['helpful'].apply(lambda x: np.nan if literal_eval(x)[1]== 0 else literal_eval(x)[0]/literal_eval(x)[1])\n",
    "    df['helpful'].fillna((df['helpful'].median()), inplace=True)\n",
    "    \n",
    "    # review counter for each review\n",
    "    df['review_count'] = 1\n",
    "\n",
    "    # Convert categorical data to their own features\n",
    "    # df = df.join(pd.get_dummies(df['root-genre']))\n",
    "    df = df.drop(columns=['root-genre'])\n",
    "\n",
    "    # Return processed data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tkgyQiZ9MD8v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "try:\n",
    "    testPath\n",
    "except NameError:\n",
    "    # Default paths of CSV files\n",
    "    print('Loading files from default locations')\n",
    "    testPath = 'Test.csv'\n",
    "    trainPath = 'Train.csv'\n",
    "\n",
    "# Load dataframes\n",
    "dfTrain = pd.read_csv(trainPath)\n",
    "if useTestCSV: dfTest = pd.read_csv(testPath)\n",
    "\n",
    "# Train text classifier on training data\n",
    "trainingTextMatrix, wordIndices = trainTextFrequency(dfTrain)\n",
    "\n",
    "# Process textual data\n",
    "if useTestCSV:\n",
    "    testTextMatrix = getTextMatrix(dfTest, wordIndices)\n",
    "\n",
    "# Process numerical data\n",
    "dfTrain = processNumerical(dfTrain)\n",
    "if useTestCSV: dfTest = processNumerical(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>amazon-id</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>artist</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4984057859803657856</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1302739200</td>\n",
       "      <td>Very nice music for practicing my Tai Chi. I d...</td>\n",
       "      <td>4</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>1</td>\n",
       "      <td>27222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9136764282801708742</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1180396800</td>\n",
       "      <td>I recently starting doing Tai Chi which I love...</td>\n",
       "      <td>5</td>\n",
       "      <td>Tranquillity In Motion !!!</td>\n",
       "      <td>16.47</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>1</td>\n",
       "      <td>27222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2164551966908582519</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1361404800</td>\n",
       "      <td>My wife uses it for her class room the kids lo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Stuff</td>\n",
       "      <td>16.47</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>1</td>\n",
       "      <td>27222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7309200698931694843</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1338163200</td>\n",
       "      <td>We bought this music to go Dr Lam DVD. The mus...</td>\n",
       "      <td>5</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>16.47</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>1</td>\n",
       "      <td>27222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4461682407031037732</td>\n",
       "      <td>1877521326299865484</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1396310400</td>\n",
       "      <td>It helps me do my exercise because it sets the...</td>\n",
       "      <td>5</td>\n",
       "      <td>tai chi music</td>\n",
       "      <td>16.47</td>\n",
       "      <td>-7180760356347753735</td>\n",
       "      <td>1</td>\n",
       "      <td>27222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111093</th>\n",
       "      <td>-508419005999372045</td>\n",
       "      <td>-272019625357917459</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>Nice soundtrack and I was pleasantly surprised...</td>\n",
       "      <td>4</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>33.76</td>\n",
       "      <td>-3758738156872779256</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111094</th>\n",
       "      <td>4690686471314282919</td>\n",
       "      <td>-272019625357917459</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1405209600</td>\n",
       "      <td>I'd you are looking for the music that they sa...</td>\n",
       "      <td>5</td>\n",
       "      <td>I'd you are looking for the music that they sa...</td>\n",
       "      <td>33.76</td>\n",
       "      <td>-3758738156872779256</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111095</th>\n",
       "      <td>-6735807132142826990</td>\n",
       "      <td>-272019625357917459</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1404259200</td>\n",
       "      <td>FANTASTIC FILM!  Loved this movie and the musi...</td>\n",
       "      <td>5</td>\n",
       "      <td>FANTASTIC FILM! Loved this movie and the music</td>\n",
       "      <td>33.76</td>\n",
       "      <td>-3758738156872779256</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111096</th>\n",
       "      <td>6536263939078780437</td>\n",
       "      <td>2197509461459270640</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1404518400</td>\n",
       "      <td>A great new CD with uptempo, funky guitar. Thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>A great new CD with uptempo</td>\n",
       "      <td>32.98</td>\n",
       "      <td>2800811401610696293</td>\n",
       "      <td>1</td>\n",
       "      <td>24972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111097</th>\n",
       "      <td>7775132336760021809</td>\n",
       "      <td>2197509461459270640</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1404691200</td>\n",
       "      <td>Great follow up CD, great smooth jazz with jus...</td>\n",
       "      <td>5</td>\n",
       "      <td>Matt Marshak does it again!</td>\n",
       "      <td>32.98</td>\n",
       "      <td>2800811401610696293</td>\n",
       "      <td>1</td>\n",
       "      <td>24972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111098 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 reviewerID            amazon-id   helpful  unixReviewTime  \\\n",
       "0      -4984057859803657856  1877521326299865484  1.000000      1302739200   \n",
       "1       9136764282801708742  1877521326299865484  1.000000      1180396800   \n",
       "2       2164551966908582519  1877521326299865484  0.875000      1361404800   \n",
       "3      -7309200698931694843  1877521326299865484  1.000000      1338163200   \n",
       "4      -4461682407031037732  1877521326299865484  0.875000      1396310400   \n",
       "...                     ...                  ...       ...             ...   \n",
       "111093  -508419005999372045  -272019625357917459  0.875000      1405900800   \n",
       "111094  4690686471314282919  -272019625357917459  0.923077      1405209600   \n",
       "111095 -6735807132142826990  -272019625357917459  0.750000      1404259200   \n",
       "111096  6536263939078780437  2197509461459270640  0.875000      1404518400   \n",
       "111097  7775132336760021809  2197509461459270640  0.875000      1404691200   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       Very nice music for practicing my Tai Chi. I d...        4   \n",
       "1       I recently starting doing Tai Chi which I love...        5   \n",
       "2       My wife uses it for her class room the kids lo...        5   \n",
       "3       We bought this music to go Dr Lam DVD. The mus...        5   \n",
       "4       It helps me do my exercise because it sets the...        5   \n",
       "...                                                   ...      ...   \n",
       "111093  Nice soundtrack and I was pleasantly surprised...        4   \n",
       "111094  I'd you are looking for the music that they sa...        5   \n",
       "111095  FANTASTIC FILM!  Loved this movie and the musi...        5   \n",
       "111096  A great new CD with uptempo, funky guitar. Thi...        5   \n",
       "111097  Great follow up CD, great smooth jazz with jus...        5   \n",
       "\n",
       "                                                  summary  price  \\\n",
       "0                                               Beautiful  16.47   \n",
       "1                              Tranquillity In Motion !!!  16.47   \n",
       "2                                             Great Stuff  16.47   \n",
       "3                                               Beautiful  16.47   \n",
       "4                                           tai chi music  16.47   \n",
       "...                                                   ...    ...   \n",
       "111093                                         Four Stars  33.76   \n",
       "111094  I'd you are looking for the music that they sa...  33.76   \n",
       "111095     FANTASTIC FILM! Loved this movie and the music  33.76   \n",
       "111096                        A great new CD with uptempo  32.98   \n",
       "111097                        Matt Marshak does it again!  32.98   \n",
       "\n",
       "                     artist  first-release-year  salesRank  review_count  \n",
       "0      -7180760356347753735                   1      27222             1  \n",
       "1      -7180760356347753735                   1      27222             1  \n",
       "2      -7180760356347753735                   1      27222             1  \n",
       "3      -7180760356347753735                   1      27222             1  \n",
       "4      -7180760356347753735                   1      27222             1  \n",
       "...                     ...                 ...        ...           ...  \n",
       "111093 -3758738156872779256                   1          6             1  \n",
       "111094 -3758738156872779256                   1          6             1  \n",
       "111095 -3758738156872779256                   1          6             1  \n",
       "111096  2800811401610696293                   1      24972             1  \n",
       "111097  2800811401610696293                   1      24972             1  \n",
       "\n",
       "[111098 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Utz6SL_dRxrk"
   },
   "outputs": [],
   "source": [
    "# Aggregate training\n",
    "isAwesome = lambda x: 1 if np.mean(x) > 4.5 else 0\n",
    "trainData = dfTrain.groupby('amazon-id').agg({\n",
    "    'unixReviewTime': 'mean',\n",
    "    'price': 'mean',\n",
    "    'overall': isAwesome,\n",
    "    'salesRank': 'mean',\n",
    "    'helpful': 'mean',\n",
    "    'first-release-year': 'mean',\n",
    "    'review_count': 'sum'\n",
    "})\n",
    "\n",
    "# normalization for numerical features\n",
    "normalize_column_data(trainData)\n",
    "\n",
    "# Aggregate testing data and split into dependent/independent vars\n",
    "if useTestCSV:\n",
    "    testData = dfTest.groupby('amazon-id').agg({\n",
    "        'unixReviewTime': 'mean',\n",
    "        'price': 'mean',\n",
    "        'salesRank': 'mean',\n",
    "        'helpful': 'mean',\n",
    "        \n",
    "        # TODO first release year\n",
    "    })\n",
    "    normalize_column_data(testData)\n",
    "    \n",
    "    ytrain = trainData['overall'].to_numpy()\n",
    "    # Todo here using review time, price and others. Let's make consistenet with \"else\" part for 'helpful only'\n",
    "    Xtrain = scipy.sparse.hstack(\n",
    "        (trainingTextMatrix, scipy.sparse.csr_matrix(trainData.drop(columns='overall').to_numpy()))\n",
    "    )\n",
    "    Xtrain = scipy.sparse.csr_matrix(Xtrain)\n",
    "    testIndex = testData.index\n",
    "    Xtest = scipy.sparse.hstack(\n",
    "        (testTextMatrix, scipy.sparse.csr_matrix(testData.to_numpy()))\n",
    "    )\n",
    "    Xtest = scipy.sparse.csr_matrix(Xtest)\n",
    "else:\n",
    "\n",
    "    ablation_columns = ['unixReviewTime', 'price', 'salesRank', 'helpful']\n",
    "    Xtrain = scipy.sparse.csr_matrix(scipy.sparse.hstack(\n",
    "        (trainingTextMatrix, scipy.sparse.csr_matrix(trainData[ablation_columns].to_numpy()))\n",
    "    ))\n",
    "    \n",
    "    ytrain = trainData['overall'].to_numpy()\n",
    "    selector = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=10000)\n",
    "    Xtrain = selector.fit_transform(Xtrain, ytrain)\n",
    "    Xtrain, Xtest, ytrain, ytest = sklearn.model_selection.train_test_split(Xtrain, trainData['overall'].to_numpy(), test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.59018057e-03, 1.08793931e-02, 4.18047761e-03, ...,\n",
       "       1.00000000e+00, 5.47640627e-02, 2.14274943e-04])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = selector.scores_\n",
    "scores /= scores.max()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b79cea40c8d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnames_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mns_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Feat_names'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F_Scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mns_df_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mns_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F_Scores'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Feat_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "names = Xtrain.columns.values[selector.get_support()]\n",
    "scores = selector.scores_[selector.get_support()]\n",
    "names_scores = list(zip(names, scores))\n",
    "ns_df = pd.DataFrame(data = names_scores, columns= ['Feat_names','F_Scores'])\n",
    "ns_df_sorted = ns_df.sort_values(['F_Scores','Feat_names'], ascending =[False, True])\n",
    "print(ns_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>overall</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>helpful</th>\n",
       "      <th>first-release-year</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9217723718720870868</th>\n",
       "      <td>0.405889</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534109</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9215746463819797371</th>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.083629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125990</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9213978596308513604</th>\n",
       "      <td>0.685361</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114240</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9211290576571923870</th>\n",
       "      <td>0.390376</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9208769561690910545</th>\n",
       "      <td>0.287381</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9218870320655141661</th>\n",
       "      <td>0.633938</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.717321</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221578337502519209</th>\n",
       "      <td>0.867375</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060813</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221615570697142155</th>\n",
       "      <td>0.678245</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.244628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221801008952598876</th>\n",
       "      <td>0.567915</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110554</td>\n",
       "      <td>0.710648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222652928856141170</th>\n",
       "      <td>0.656021</td>\n",
       "      <td>0.023037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>0.814145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10543 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      unixReviewTime     price  overall  salesRank   helpful  \\\n",
       "amazon-id                                                                      \n",
       "-9217723718720870868        0.405889  0.017195      0.0   0.534109  0.620370   \n",
       "-9215746463819797371        0.764063  0.083629      1.0   0.125990  0.937500   \n",
       "-9213978596308513604        0.685361  0.027558      0.0   0.114240  0.666667   \n",
       "-9211290576571923870        0.390376  0.030183      0.0   0.131090  1.000000   \n",
       "-9208769561690910545        0.287381  0.020846      0.0   0.007136  0.812500   \n",
       "...                              ...       ...      ...        ...       ...   \n",
       " 9218870320655141661        0.633938  0.015613      0.0   0.717321  0.500000   \n",
       " 9221578337502519209        0.867375  0.023333      1.0   0.060813  0.921875   \n",
       " 9221615570697142155        0.678245  0.024637      1.0   0.244628  1.000000   \n",
       " 9221801008952598876        0.567915  0.027836      0.0   0.110554  0.710648   \n",
       " 9222652928856141170        0.656021  0.023037      0.0   0.240380  0.814145   \n",
       "\n",
       "                      first-release-year  review_count  \n",
       "amazon-id                                               \n",
       "-9217723718720870868                 0.0       0.00416  \n",
       "-9215746463819797371                 1.0       0.00156  \n",
       "-9213978596308513604                 0.0       0.00000  \n",
       "-9211290576571923870                 1.0       0.00052  \n",
       "-9208769561690910545                 1.0       0.00780  \n",
       "...                                  ...           ...  \n",
       " 9218870320655141661                 1.0       0.00052  \n",
       " 9221578337502519209                 1.0       0.00364  \n",
       " 9221615570697142155                 1.0       0.00052  \n",
       " 9221801008952598876                 1.0       0.00884  \n",
       " 9222652928856141170                 1.0       0.00572  \n",
       "\n",
       "[10543 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_JlvVY9yDVg",
    "outputId": "649deefa-008f-4efe-8e6c-302084edc84f",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7294109811503363\n",
      "SVM\n",
      "F1 0.7248583406192396\n",
      "voting\n",
      "F1 0.7282510349156398\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.754692369274344\n",
      "SVM\n",
      "F1 0.7570851607194893\n",
      "voting\n",
      "F1 0.7548873250618795\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7604411584185528\n",
      "SVM\n",
      "F1 0.7625733817281621\n",
      "voting\n",
      "F1 0.7632515829651668\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7597917071320884\n",
      "SVM\n",
      "F1 0.7616686968263411\n",
      "voting\n",
      "F1 0.7627329747682449\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7650052876533713\n",
      "SVM\n",
      "F1 0.7679330991215153\n",
      "voting\n",
      "F1 0.7651213187696245\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.761756450385717\n",
      "SVM\n",
      "F1 0.7588075880758808\n",
      "voting\n",
      "F1 0.7619798988282542\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7660811625195034\n",
      "SVM\n",
      "F1 0.7635796044622989\n",
      "voting\n",
      "F1 0.7608744168943115\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7683437414084285\n",
      "SVM\n",
      "F1 0.7707367433720794\n",
      "voting\n",
      "F1 0.7657348407949917\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7518258510884716\n",
      "SVM\n",
      "F1 0.7542241096889447\n",
      "voting\n",
      "F1 0.753221353908888\n",
      "==================================================\n",
      "logistic regression\n",
      "F1 0.7494574851763556\n",
      "SVM\n",
      "F1 0.7597079642869627\n",
      "voting\n",
      "F1 0.7508536113423475\n",
      "Mean F1 LR:  0.7566806194207168\n",
      "Mean F1 SVM:  0.7581174688900914\n",
      "Mean F1 voting:  0.7566908358249348\n"
     ]
    }
   ],
   "source": [
    "voting_flag = True\n",
    "\n",
    "# Testing\n",
    "if not useTestCSV:\n",
    "    # Run ML\n",
    "    kf = sklearn.model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    #kf = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
    "    f1_vals_log = []\n",
    "    f1_vals_rnd = []\n",
    "    f1_vals_svm = []\n",
    "    f1_vals_gnb = []\n",
    "    f1_vals_voting = []\n",
    "    \n",
    "    #log_clf = sklearn.linear_model.LogisticRegression(max_iter=100000, class_weight='balanced')\n",
    "    log_clf = sklearn.linear_model.LogisticRegression(max_iter=100000, multi_class='multinomial', C=1.0, class_weight='balanced', penalty='l2')\n",
    "    # for soft\n",
    "    #svm_rbf_clf = SVC(kernel='linear', probability=True)\n",
    "    # for hard\n",
    "    #svm_rbf_clf = SVC(kernel='linear')\n",
    "    svm_rbf_clf = SVC(C=1.1, class_weight='balanced', kernel='linear', max_iter=5000000)\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "    MNBclf = MultinomialNB()\n",
    "    gnb_clf = sklearn.naive_bayes.GaussianNB()\n",
    "    #voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svm', svm_rbf_clf)], voting='hard')\n",
    "    voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('svm', svm_rbf_clf)], voting='hard')\n",
    "    \n",
    "    # ('gnb', gnb_clf)\n",
    "    #clf_list = [log_clf, rnd_clf, svm_rbf_clf, voting_clf]\n",
    "    clf_list = [log_clf, svm_rbf_clf, voting_clf]\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xtrain):\n",
    "        x_train, x_test = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train, y_test = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        if voting_flag:\n",
    "            print(\"==================================================\")\n",
    "            for clf in clf_list:\n",
    "                clt = clf.fit(x_train, y_train)\n",
    "                f1 = sklearn.metrics.f1_score(y_test, clt.predict(x_test), average='weighted')\n",
    "\n",
    "                if clf == log_clf:\n",
    "                    print(\"logistic regression\")\n",
    "                    f1_vals_log.append(f1)\n",
    "                elif clf == rnd_clf:\n",
    "                    print(\"random forest\")\n",
    "                    f1_vals_rnd.append(f1)\n",
    "                elif clf == gnb_clf:\n",
    "                    print(\"Gaussian Naive\")\n",
    "                    f1_vals_gnb.append(f1)\n",
    "                elif clf == svm_rbf_clf:\n",
    "                    print(\"SVM\")\n",
    "                    f1_vals_svm.append(f1)\n",
    "                else:\n",
    "                    print(\"voting\")\n",
    "                    f1_vals_voting.append(f1)\n",
    "                print(\"F1 {}\".format(f1))\n",
    "\n",
    "        else:\n",
    "            clt = log_clf.fit(x_train, y_train)\n",
    "            f1 = sklearn.metrics.f1_score(y_test, clt.predict(x_test), average='weighted')\n",
    "            f1_vals_log.append(f1)\n",
    "            print(\"F1 {}\".format(f1))\n",
    "\n",
    "    if voting_flag:    \n",
    "        print(\"Mean F1 LR: \", statistics.mean(f1_vals_log))\n",
    "        #print(\"Mean F1 RF: \", statistics.mean(f1_vals_rnd))\n",
    "        print(\"Mean F1 SVM: \", statistics.mean(f1_vals_svm))\n",
    "        print(\"Mean F1 voting: \", statistics.mean(f1_vals_voting))\n",
    "    else:\n",
    "        print(\"Mean F1 LR: \", statistics.mean(f1_vals_log))\n",
    "    # print(sklearn.metrics.f1_score(ytest, ypreds, average='weighted'))\n",
    "\n",
    "# Output CSV file with predictions\n",
    "if useTestCSV:\n",
    "\n",
    "    LR = sklearn.linear_model.LogisticRegression(max_iter=100000, class_weight='balanced')\n",
    "    LRTrained = LR.fit(Xtrain, ytrain)\n",
    "    ypreds = LRTrained.predict(Xtest)\n",
    "    # Output predictions for deliverable\n",
    "    output = pd.DataFrame({'amazon-id': testIndex, 'Awesome': ypreds})\n",
    "    output.to_csv('./Product_Predictions.csv')\n",
    "    print(\"Output to ./Product_Predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Testing\\nif not useTestCSV:\\n    # Run ML\\n    kf = sklearn.model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\\n    #kf = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\\n    f1_vals_log = []\\n    f1_vals_rnd = []\\n    f1_vals_svm = []\\n    f1_vals_gnb = []\\n    f1_vals_voting = []\\n    f1_vals_bagging = []\\n    \\n    log_clf = sklearn.linear_model.LogisticRegression(max_iter=100000, class_weight=\\'balanced\\')\\n    # for soft\\n    #svm_rbf_clf = SVC(kernel=\\'linear\\', probability=True)\\n    # for hard\\n    svm_rbf_clf = SVC(kernel=\\'linear\\')\\n    rnd_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\\n    MNBclf = MultinomialNB()\\n    gnb_clf = sklearn.naive_bayes.GaussianNB()\\n    #voting_clf = VotingClassifier(estimators=[(\\'lr\\', log_clf), (\\'rf\\', rnd_clf), (\\'svm\\', svm_rbf_clf)], voting=\\'hard\\')\\n    voting_clf = VotingClassifier(estimators=[(\\'lr\\', log_clf), (\\'rf\\', rnd_clf), (\\'svm\\', svm_rbf_clf)], voting=\\'hard\\')\\n    \\n    # Bagging classifier\\n    bag_clf = BaggingClassifier(\\n        rnd_clf, n_estimators=500, max_samples=3000, bootstrap=True, n_jobs=-1)\\n    \\n    for train_index, test_index in kf.split(Xtrain):\\n        x_train, x_test = Xtrain[train_index], Xtrain[test_index]\\n        y_train, y_test = ytrain[train_index], ytrain[test_index]\\n        \\n        print(\"==================================================\")\\n        bag_clf.fit(x_train, y_train)\\n        f1 = sklearn.metrics.f1_score(y_test, bag_clf.predict(x_test), average=\\'weighted\\')\\n        f1_vals_bagging.append(f1)\\n        print(\"F1 {}\".format(f1))\\n        \\n    print(\"Mean F1 bagging: \", statistics.mean(f1_vals_bagging))\\n    #print(\"Mean F1 LR: \", statistics.mean(f1_vals_log))\\n    #print(\"Mean F1 RF: \", statistics.mean(f1_vals_rnd))\\n    #print(\"Mean F1 SVM: \", statistics.mean(f1_vals_svm))\\n    #print(\"Mean F1 voting: \", statistics.mean(f1_vals_voting))\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Testing\n",
    "if not useTestCSV:\n",
    "    # Run ML\n",
    "    kf = sklearn.model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    #kf = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
    "    f1_vals_log = []\n",
    "    f1_vals_rnd = []\n",
    "    f1_vals_svm = []\n",
    "    f1_vals_gnb = []\n",
    "    f1_vals_voting = []\n",
    "    f1_vals_bagging = []\n",
    "    \n",
    "    log_clf = sklearn.linear_model.LogisticRegression(max_iter=100000, class_weight='balanced')\n",
    "    # for soft\n",
    "    #svm_rbf_clf = SVC(kernel='linear', probability=True)\n",
    "    # for hard\n",
    "    svm_rbf_clf = SVC(kernel='linear')\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "    MNBclf = MultinomialNB()\n",
    "    gnb_clf = sklearn.naive_bayes.GaussianNB()\n",
    "    #voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svm', svm_rbf_clf)], voting='hard')\n",
    "    voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svm', svm_rbf_clf)], voting='hard')\n",
    "    \n",
    "    # Bagging classifier\n",
    "    bag_clf = BaggingClassifier(\n",
    "        rnd_clf, n_estimators=500, max_samples=3000, bootstrap=True, n_jobs=-1)\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xtrain):\n",
    "        x_train, x_test = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train, y_test = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        print(\"==================================================\")\n",
    "        bag_clf.fit(x_train, y_train)\n",
    "        f1 = sklearn.metrics.f1_score(y_test, bag_clf.predict(x_test), average='weighted')\n",
    "        f1_vals_bagging.append(f1)\n",
    "        print(\"F1 {}\".format(f1))\n",
    "        \n",
    "    print(\"Mean F1 bagging: \", statistics.mean(f1_vals_bagging))\n",
    "    #print(\"Mean F1 LR: \", statistics.mean(f1_vals_log))\n",
    "    #print(\"Mean F1 RF: \", statistics.mean(f1_vals_rnd))\n",
    "    #print(\"Mean F1 SVM: \", statistics.mean(f1_vals_svm))\n",
    "    #print(\"Mean F1 voting: \", statistics.mean(f1_vals_voting))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2000 year: 0.718\n",
    "# only helpful: 0.720\n",
    "\n",
    "# hard: increase\n",
    "# soft: decrease\n",
    "# without estimation decrease 0.726"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "deliverable-3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
