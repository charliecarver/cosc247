{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "## Run in Google Colab:\n",
    "https://colab.research.google.com/github/charliecarver/cosc247/blob/master/deliverable-3/deliverable-3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYIr7Z6djAq1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load CSV files from remote repo\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "r = requests.get('https://github.com/charliecarver/cosc247/blob/master/datasets.zip?raw=true')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "testPath = 'Test.csv'\n",
    "trainPath = 'Train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-File Deliverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import sklearn.metrics\n",
    "import sklearn.naive_bayes\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from timeit import default_timer as timer\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Train text classifier\n",
    "def trainTextPredictor(df):\n",
    "    return None, None\n",
    "\n",
    "# Predict sentiment\n",
    "def processTextual(classifier, wordIndices, df):\n",
    "    df2 = pd.DataFrame(0, index=range(len(df.index)), columns=['summary-positive', 'review-positive'])\n",
    "    return df.join(df2)\n",
    "\n",
    "# function for normalization\n",
    "def normalize_column_data(input_data):\n",
    "    numerical_feautures = ['unixReviewTime','price', 'salesRank', 'helpful']\n",
    "    for feature in numerical_feautures:    \n",
    "        input_data[feature] = (input_data[feature]-input_data[feature].min())/(input_data[feature].max()-input_data[feature].min())\n",
    "\n",
    "# Process numerical data\n",
    "def processNumerical(df):\n",
    "\n",
    "    # Drop text data\n",
    "    df = df.drop(columns=['title', 'reviewText', 'summary', 'categories', 'songs', 'related', 'reviewTime'])\n",
    "\n",
    "    # Drop columns that need more time to process\n",
    "    df = df.drop(columns=['label', 'first-release-year'])\n",
    "\n",
    "    # Transform helpful into \"ratio\" of being helpful\n",
    "    df['helpful'] = df['helpful'].apply(lambda x: np.nan if literal_eval(x)[1]== 0 else literal_eval(x)[0]/literal_eval(x)[1])\n",
    "    df['helpful'].fillna((df['helpful'].median()), inplace=True)\n",
    "\n",
    "    # Convert categorical data to their own features\n",
    "    # df = df.join(pd.get_dummies(df['root-genre']))\n",
    "    df = df.drop(columns=['root-genre'])\n",
    "\n",
    "    # Return processed data\n",
    "    return df\n",
    "\n",
    "# Flag to set mode\n",
    "useTestCSV = False\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    testPath\n",
    "except NameError:\n",
    "    # Default paths of CSV files\n",
    "    print('Loading files from default locations')\n",
    "    testPath = 'Test.csv'\n",
    "    trainPath = 'Train.csv'\n",
    "\n",
    "# Load dataframes\n",
    "dfTrain = pd.read_csv(trainPath)\n",
    "if useTestCSV: dfTest = pd.read_csv(testPath)\n",
    "\n",
    "# Train text classifier on training data\n",
    "textClassifier, wordIndices = trainTextPredictor(dfTrain)\n",
    "\n",
    "# Process textual data\n",
    "dfTrain = processTextual(textClassifier, wordIndices, dfTrain)\n",
    "if useTestCSV: dfTest = processTextual(textClassifier, wordIndices, dfTest)\n",
    "\n",
    "# Process numerical data\n",
    "dfTrain = processNumerical(dfTrain)\n",
    "if useTestCSV: dfTest = processNumerical(dfTest)\n",
    "\n",
    "# Aggregate training\n",
    "isAwesome = lambda x: 1 if np.mean(x) > 4.5 else 0\n",
    "trainData = dfTrain.groupby('amazon-id').agg({\n",
    "    'unixReviewTime': 'mean',\n",
    "    'price': 'mean',\n",
    "    'overall': isAwesome,\n",
    "    'salesRank': 'mean',\n",
    "    'helpful': 'mean',\n",
    "    'summary-positive': 'sum',\n",
    "    'review-positive': 'sum'\n",
    "})\n",
    "\n",
    "# normalization for numerical features\n",
    "normalize_column_data(trainData)\n",
    "\n",
    "# Aggregate testing data and split into dependent/independent vars\n",
    "if useTestCSV:\n",
    "    testData = dfTest.groupby('amazon-id').agg({\n",
    "        'unixReviewTime': 'mean',\n",
    "        'price': 'mean',\n",
    "        'salesRank': 'mean',\n",
    "        'helpful': 'mean',\n",
    "        'summary-positive': 'sum',\n",
    "        'review-positive': 'sum'\n",
    "    })\n",
    "    normalize_column_data(testData)\n",
    "    Xtrain, ytrain = trainData.drop(columns='overall'), trainData['overall']\n",
    "    Xtest, ytest = testData, []\n",
    "else:\n",
    "    trainData, testData = sklearn.model_selection.train_test_split(trainData, test_size=0.3, shuffle=True)\n",
    "    Xtrain, ytrain = trainData.drop(columns='overall'), trainData['overall']\n",
    "    Xtest, ytest = testData.drop(columns='overall'), testData['overall']\n",
    "\n",
    "# Run ML\n",
    "\"\"\"\n",
    "gnb = sklearn.naive_bayes.GaussianNB()\n",
    "gnbTrained = gnb.fit(Xtrain, ytrain)\n",
    "preds = gnbTrained.predict(Xtest)\n",
    "\"\"\"\n",
    "\n",
    "# only for numerical data best model\n",
    "Xnumerical_best_train = Xtrain['helpful'].to_numpy().reshape(-1,1)\n",
    "Xnumerical_best_test = Xtest['helpful'].to_numpy().reshape(-1,1)\n",
    "tree_clf = sklearn.tree.DecisionTreeClassifier(max_depth=4)\n",
    "tree_trained = tree_clf.fit(Xnumerical_best_train, ytrain)\n",
    "ypreds = tree_trained.predict(Xnumerical_best_test)\n",
    "\n",
    "# Testing\n",
    "if not useTestCSV:\n",
    "    print(sklearn.metrics.f1_score(ytest, ypreds, average='weighted'))\n",
    "\n",
    "# Output CSV file with predictions\n",
    "if useTestCSV:\n",
    "\n",
    "    # Output predictions for deliverable\n",
    "    output = pd.DataFrame({'amazon-id': Xtest.index, 'Awesome': preds})\n",
    "    output.to_csv('./Product_Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted score list: [0.60724904 0.59836392 0.64437124 0.62662451 0.62482607]\n",
      "f1_weighted score average: 0.6202869571318353\n",
      "accuracy score list: [0.63550136 0.61517615 0.63685637 0.62940379 0.64701897]\n",
      "accuracy score average: 0.6327913279132791\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with K fold for numerical data performance only\n",
    "Xnumerical_best_train = Xtrain['helpful']\n",
    "Xnumerical_best_train = Xnumerical_best_train.to_numpy().reshape(-1,1)\n",
    "kfold = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "tree_clf = sklearn.tree.DecisionTreeClassifier(max_depth=4)\n",
    "cv_results_acc = model_selection.cross_val_score(tree_clf, Xtrain, ytrain.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "cv_results_f1 = model_selection.cross_val_score(tree_clf, Xtrain, ytrain.values.ravel(), cv=kfold, scoring='f1_weighted')\n",
    "print(\"f1_weighted score list: {}\".format(cv_results_f1))\n",
    "print(\"f1_weighted score average: {}\".format(np.mean(cv_results_f1)))  \n",
    "print(\"accuracy score list: {}\".format(cv_results_acc))\n",
    "print(\"accuracy score average: {}\".format(np.mean(cv_results_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "deliverable-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
