{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "deliverable-3.ipynb",
   "provenance": [],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "## Run in Google Colab:\n",
    "https://colab.research.google.com/github/charliecarver/cosc247/blob/master/deliverable-3/deliverable-3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "OYIr7Z6djAq1"
   },
   "source": [
    "# Load CSV files from remote repo\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "r = requests.get('https://github.com/charliecarver/cosc247/blob/master/datasets.zip?raw=true')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "testPath = 'Test.csv'\n",
    "trainPath = 'Train.csv'"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single-File Deliverable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0         1\n1         1\n2         1\n3         1\n4         1\n         ..\n111093    1\n111094    1\n111095    1\n111096    1\n111097    1\nName: target, Length: 111098, dtype: int64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "# Normalize a pandas column\n",
    "def normalize(column):\n",
    "    return (column-column.min())/(column.max()-column.min())\n",
    "\n",
    "# Define target\n",
    "def setTarget(df):\n",
    "    df['target'] = 0\n",
    "    df.loc[df['overall'] >= 4, 'target'] = 1\n",
    "    return df.drop(columns=['overall'])\n",
    "\n",
    "# Process numerical data\n",
    "def processNumerical(df):\n",
    "\n",
    "    # Drop text data\n",
    "    df = df.drop(columns=['title', 'reviewText', 'summary', 'categories', 'songs', 'related'])\n",
    "\n",
    "    # Transform helpful into \"ratio\" of being helpful\n",
    "    df['helpful'] = df['helpful'].apply(lambda x: 0.5 if literal_eval(x)[1]== 0 else literal_eval(x)[0]/literal_eval(x)[1])\n",
    "\n",
    "    # Convert categorical data to their own features\n",
    "    df = df.join(pd.get_dummies(df['root-genre']))\n",
    "    df = df.drop(columns=['root-genre'])\n",
    "    df = df.join(pd.get_dummies(df['label']))\n",
    "    df = df.drop(columns=['label'])\n",
    "\n",
    "    # Normalize other numerical columns\n",
    "    df['price'] = normalize(df['price'])\n",
    "    df['salesRank'] = normalize(df['salesRank'])\n",
    "    df['first-release-year'] = normalize(df['first-release-year'])\n",
    "    df['unixReviewTime'] = normalize(df['unixReviewTime'])\n",
    "\n",
    "    # Return processed data\n",
    "    return df\n",
    "\n",
    "# Process textual data\n",
    "def processTextual(df):\n",
    "    return df\n",
    "\n",
    "# Drop any empty/NaN rows\n",
    "def dropEmpty(df):\n",
    "    return df\n",
    "\n",
    "# Split into data and target matrices\n",
    "def splitData(df):\n",
    "    target = df['target']\n",
    "    data = df.drop(columns=['target'])\n",
    "    return data, target\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    testPath\n",
    "except NameError:\n",
    "    # Default paths of CSV files\n",
    "    print('Loading files from default locations')\n",
    "    testPath = 'Test.csv'\n",
    "    trainPath = 'Train.csv'\n",
    "\n",
    "# Load dataframe\n",
    "df = pd.read_csv(trainPath)\n",
    "df = setTarget(df)\n",
    "# df = processNumerical(df)\n",
    "df = processTextual(df)\n",
    "df = dropEmpty(df)\n",
    "data, target = splitData(df)\n",
    "\n",
    "# Train\n",
    "# X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(quant_data, predicted_variable, test_size=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}